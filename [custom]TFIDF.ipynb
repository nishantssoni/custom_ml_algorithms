{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e69274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tfidfvec:\n",
    "    features = []\n",
    "    idf_ = []\n",
    "    feature_counts = dict()\n",
    "    corpus = []\n",
    "    numberofdocuments = 0\n",
    "    tfidf = []\n",
    "    tf = []\n",
    "    vocabulary_ = {}\n",
    "    \n",
    "    def fit(self,cor):\n",
    "        \"\"\"fit method similar to sklearn fit vectoriser\"\"\"\n",
    "        self.corpus = cor\n",
    "        self.numberofdocuments = len(self.corpus)\n",
    "        count_t = []\n",
    "        \n",
    "        # adding different word in corpus and all word in count_t variable\n",
    "        for s in cor:\n",
    "            for w in s.split():\n",
    "                count_t.append(w)\n",
    "                if w not in self.features:\n",
    "                    self.features.append(w)\n",
    "        # sorting features alphabetacly and storing all the word count in features_count\n",
    "        self.features.sort()\n",
    "        self.feature_counts = dict(Counter(count_t))\n",
    "        \n",
    "        # removing extra count in feature_count if a word occour more the one time\n",
    "        count = 0\n",
    "        for x in self.corpus:\n",
    "            for y in self.feature_counts:\n",
    "                count = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(y), x))\n",
    "                if count > 1:\n",
    "                    self.feature_counts[y] -= count - 1\n",
    "        \n",
    "        # calculating idf for features and storing in idf_ attribute\n",
    "        for wrd in tqdm(self.features):\n",
    "            result = 1 + math.log( (1 + self.numberofdocuments) / (1 + self.feature_counts[wrd]) )\n",
    "            self.idf_.append(result)\n",
    "            \n",
    "            \n",
    "        # converting into numpy array\n",
    "        self.features = np.array(self.features)\n",
    "        self.idf_ = np.array(self.idf_)\n",
    "        \n",
    "        # vocbulary_\n",
    "        index = 0\n",
    "        for i in self.features:\n",
    "            self.vocabulary_[i] = index\n",
    "            index += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # transform function\n",
    "    def transform(self, cor):\n",
    "        for sen in cor:\n",
    "            for wrd in self.get_feature_names():\n",
    "                count = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(wrd), sen))\n",
    "                result = count / ( len( sen.split() ) )\n",
    "                self.tf.append(result)\n",
    "                \n",
    "        # tfidf valueas storing in temp_tfidf_values\n",
    "        for i in tqdm(range(len(self.corpus))):\n",
    "            current_arr = []\n",
    "            for j in range(len(self.features)):\n",
    "                result = self.tf[i*(len(self.features))+j] * self.idf_[j]\n",
    "                current_arr.append(result)\n",
    "            self.tfidf.append(current_arr)\n",
    "        \n",
    "        # l2 normalization\n",
    "        self.tfidf = csr_matrix(self.tfidf)\n",
    "        self.tfidf = normalize(self.tfidf,'l2',axis=1)\n",
    "        return self.tfidf\n",
    "    \n",
    "    # get feature name\n",
    "    def get_feature_names(self):\n",
    "        return list(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83caafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "'this is the first document',\n",
    "'this document is the second document',\n",
    "'and this is the third one',\n",
    "'is this the first document',\n",
    "]\n",
    "\n",
    "vectorizer = tfidfvec()\n",
    "vectorizer.fit(corpus)\n",
    "skl_output = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63693a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca74bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.22314355, 1.51082562, 1.        , 1.91629073,\n",
       "       1.91629073, 1.        , 1.91629073, 1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7b4e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c799324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999c1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n"
     ]
    }
   ],
   "source": [
    "print(skl_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02b7be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]]\n"
     ]
    }
   ],
   "source": [
    "print(skl_output[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fec94d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'is': 3,\n",
       " 'one': 4,\n",
       " 'second': 5,\n",
       " 'the': 6,\n",
       " 'third': 7,\n",
       " 'this': 8}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8a771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
